{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee7d87AQd4qI"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 6px solid #C2172D;\">\n",
        "    <h2 style=\"color: black\" id=\"introduction\">Batch Data Processing with Apache Spark</h2>\n",
        "    <p></p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5nw1CD5nfWU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdroxOMRd4qK"
      },
      "source": [
        "## [Contents](#contents)\n",
        "1. [Introduction](#introduction)\n",
        "2. [Importing the libraries](#library)\n",
        "3. [Reading the data](#read_data)\n",
        "4. [SparkSQL Practices](#spark_sql_practices)\n",
        "   * [Selecting columns](#selecting_columns)\n",
        "   * [Data manipulation](#data_manipulation)\n",
        "   * [Filtering rows](#filtering_rows)\n",
        "   * [Aggregating data](#aggregating_data)\n",
        "   * [Joining](#joining)\n",
        "5. [Case Studies](#assignments)\n",
        "   * [Assignment 1: Jacket sales per region](#assignment_1)\n",
        "   * [Assignment 2: Maximum turnover of the retailer regions](#assignment_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyOo4SK9d4qM"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 4px solid #C2172D;\">\n",
        "    <a id=\"introduction\">\n",
        "        <h3 style=\"color: #C2172D\">1. Introduction</h3>\n",
        "    </a>  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWC8_p0Id4qM"
      },
      "source": [
        "<img src=\"assets/img/data_model.svg\"  style=\"width:1000px; padding: 20px\"/>\n",
        "\n",
        "#### SQL Tables Description\n",
        "- **FactSale:** Sales transactions fact table\n",
        "- **FactPurchase:** Purchases fact table\n",
        "- **DimRetailer:** Retailer details dimension table\n",
        "- **DimCustomer:** Customer details dimension table\n",
        "- **DimProduct:** Product details dimension table\n",
        "- **DimRegion:** Region details dimension table\n",
        "- **DimDate:** Date dimension table\n",
        "- **DimSupplier:** Supplier details dimension table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaoyHM-Qd4qN"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 4px solid #C2172D;\">\n",
        "    <a id=\"library\">\n",
        "        <h3 style=\"color: #C2172D\">2. Importing the libraries</h3>\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtdeyq_Qd4qN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession, functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqdZc33id4qO",
        "outputId": "9fc42f90-c9cd-4737-968e-5d718382fb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z4iNNIRd4qO"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 4px solid #C2172D;\">\n",
        "    <a id=\"read_data\">\n",
        "        <h3 style=\"color: #C2172D\">3. Reading the data</h3>\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJXNX1nEd4qP"
      },
      "outputs": [],
      "source": [
        "# Creating new SparkSession instance\n",
        "spark = SparkSession.builder.appName(\"PySparkExample\").getOrCreate()\n",
        "\n",
        "# Reading parquet data and assigning to DataFrame variables\n",
        "df_ret = spark.read.parquet(\"/content/retail.parquet\")\n",
        "df_cus = spark.read.parquet(\"/content/part-00000-0eb2cc7e-9512-4a03-89b7-838575beabff-c000.snappy.parquet\")\n",
        "df_pur = spark.read.parquet(\"/content/part-00000-29203130-0a81-43a4-9c6f-5c9f50912c86-c000.snappy.parquet\")\n",
        "df_sal = spark.read.parquet(\"/content/sale.parquet\")\n",
        "\n",
        "\n",
        "df_pro = spark.read.parquet(\"/content/product.parquet\")\n",
        "df_sup = spark.read.parquet(\"/content/supplier.parquet\")\n",
        "df_reg = spark.read.parquet(\"/content/region.parquet\")\n",
        "df_date = spark.read.parquet(\"/content/date.parquet\")\n",
        "\n",
        "# Creating temporary view tables for Spark SQL queries\n",
        "df_cus.createOrReplaceTempView(\"DimCustomer\")\n",
        "df_pur.createOrReplaceTempView(\"FactPurchase\")\n",
        "df_sal.createOrReplaceTempView(\"FactSale\")\n",
        "df_ret.createOrReplaceTempView(\"DimRetailer\")\n",
        "df_pro.createOrReplaceTempView(\"DimProduct\")\n",
        "df_sup.createOrReplaceTempView(\"DimSupplier\")\n",
        "df_reg.createOrReplaceTempView(\"DimRegion\")\n",
        "df_date.createOrReplaceTempView(\"DimDate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhWWB_utd4qP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PySparkExample\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bB5hdjDd4qP"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 4px solid #C2172D;\">\n",
        "    <a id=\"spark_sql_practices\">\n",
        "        <h3 style=\"color: #C2172D\">4. Spark SQL Practices</h3>\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ktWFB_md4qP"
      },
      "source": [
        "**<a id=\"selecting_columns\">Selecting columns</a>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgwOiML8d4qP",
        "outputId": "9020b464-f8d0-4c35-8af1-7ed12c997511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+----------+\n",
            "|customer_id|   name| surname|birth_date|\n",
            "+-----------+-------+--------+----------+\n",
            "|          1| Jazmin|  Burril|1958-09-22|\n",
            "|          2| Dalila|   Faers|2000-11-08|\n",
            "|          3|Wayland|Walework|1976-03-08|\n",
            "|          4|Amberly|  Haquin|1948-10-08|\n",
            "|          5|Garrett|   Frear|1957-09-25|\n",
            "+-----------+-------+--------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT customer_id, name, surname, birth_date FROM DimCustomer LIMIT 5\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSezz_qud4qQ",
        "outputId": "be800fb7-f1af-4522-9d34-a1cfeddff77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+----------+\n",
            "|customer_id|   name| surname|birth_date|\n",
            "+-----------+-------+--------+----------+\n",
            "|          1| Jazmin|  Burril|1958-09-22|\n",
            "|          2| Dalila|   Faers|2000-11-08|\n",
            "|          3|Wayland|Walework|1976-03-08|\n",
            "|          4|Amberly|  Haquin|1948-10-08|\n",
            "|          5|Garrett|   Frear|1957-09-25|\n",
            "+-----------+-------+--------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cus.select(\"customer_id\", \"name\", \"surname\", \"birth_date\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdyHk5lbd4qQ"
      },
      "source": [
        "**<a id=\"data_manipulation\">Data manipulation: </a>** Calculating the ages from date of birth data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZJYhZ8Fd4qQ",
        "outputId": "6e7244b4-2ecb-470d-a21b-4ced1027f05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+---+\n",
            "|customer_id|   name| surname|age|\n",
            "+-----------+-------+--------+---+\n",
            "|          1| Jazmin|  Burril| 67|\n",
            "|          2| Dalila|   Faers| 25|\n",
            "|          3|Wayland|Walework| 49|\n",
            "|          4|Amberly|  Haquin| 77|\n",
            "|          5|Garrett|   Frear| 68|\n",
            "+-----------+-------+--------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    customer_id\n",
        "    ,name\n",
        "    ,surname\n",
        "    ,YEAR(CURRENT_DATE()) - YEAR(birth_date) AS age\n",
        "FROM DimCustomer\n",
        "LIMIT 5\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHe98aESd4qQ",
        "outputId": "edd6e2d1-5ed4-4d1a-fce8-5465fad95f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+---+\n",
            "|customer_id|   name| surname|age|\n",
            "+-----------+-------+--------+---+\n",
            "|          1| Jazmin|  Burril| 67|\n",
            "|          2| Dalila|   Faers| 25|\n",
            "|          3|Wayland|Walework| 49|\n",
            "|          4|Amberly|  Haquin| 77|\n",
            "|          5|Garrett|   Frear| 68|\n",
            "+-----------+-------+--------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    df_cus.withColumn(\"age\", F.year(F.current_date()) - F.year(\"birth_date\"))\n",
        "    .select(\"customer_id\", \"name\", \"surname\", \"age\")\n",
        "    .show(5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08CFW4qQd4qQ"
      },
      "source": [
        "**<a id=\"filtering_rows\">Filtering rows</a>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-DzhWnmd4qQ",
        "outputId": "e4fc589f-e6a9-4b79-f526-36eb68f98d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+\n",
            "|   name| surname|age|\n",
            "+-------+--------+---+\n",
            "| Jazmin|  Burril| 67|\n",
            "|Wayland|Walework| 49|\n",
            "|Amberly|  Haquin| 77|\n",
            "|Garrett|   Frear| 68|\n",
            "|  Horst|   Isted| 50|\n",
            "+-------+--------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    name\n",
        "    ,surname\n",
        "    ,age\n",
        "FROM\n",
        "(\n",
        "    SELECT\n",
        "        customer_id\n",
        "        ,name\n",
        "        ,surname\n",
        "        ,YEAR(CURRENT_DATE()) - YEAR(birth_date) AS age\n",
        "    FROM DimCustomer\n",
        ")\n",
        "WHERE age >= 30\n",
        "LIMIT 5\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Nk9RBwd4qQ",
        "outputId": "e64ae325-d821-4a0a-a403-fb2006e73efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+\n",
            "|   name| surname|age|\n",
            "+-------+--------+---+\n",
            "| Jazmin|  Burril| 67|\n",
            "|Wayland|Walework| 49|\n",
            "|Amberly|  Haquin| 77|\n",
            "|Garrett|   Frear| 68|\n",
            "|  Horst|   Isted| 50|\n",
            "+-------+--------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    df_cus.withColumn(\"age\", F.year(F.current_date()) - F.year(\"birth_date\"))\n",
        "    .select(\"name\", \"surname\", \"age\")\n",
        "    .filter(F.col(\"age\") >= 30)\n",
        "    .show(5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tas1OG5d4qR"
      },
      "source": [
        "**<a id=\"aggregating_data\">Aggregating data</a>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyOMMEIud4qR",
        "outputId": "890429d4-3356-4f98-b75e-baab78a30b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+------------+\n",
            "|order_id|total_quantity|total_amount|\n",
            "+--------+--------------+------------+\n",
            "|    3647|            13|         521|\n",
            "|    2574|            13|         488|\n",
            "|    3515|            13|         402|\n",
            "|     101|            12|         359|\n",
            "|     440|            12|         426|\n",
            "|    3763|            12|         323|\n",
            "|    1585|            12|         488|\n",
            "|    3289|            12|         327|\n",
            "|    2337|            11|         357|\n",
            "|    3743|            11|         359|\n",
            "+--------+--------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    df_sal.groupBy(\"order_id\").agg(\n",
        "        F.sum(\"quantity\").alias(\"total_quantity\"),\n",
        "        F.sum(\"total_amt\").alias(\"total_amount\")\n",
        "    ).orderBy(\"total_quantity\", ascending=False)\n",
        "    .show(10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n57zvTX0d4qR"
      },
      "source": [
        "**<a id=\"joining\">Joining</a>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qWZhsIWd4qR",
        "outputId": "da2bcc4b-7039-47f5-8ad3-a3d860d3b49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------------+\n",
            "|      region_name|               age|\n",
            "+-----------------+------------------+\n",
            "|          Akdeniz| 51.81521739130435|\n",
            "|     Dogu Anadolu| 51.13095238095238|\n",
            "|Guneydogu Anadolu| 49.58119658119658|\n",
            "|          Marmara|49.189542483660134|\n",
            "|       Ic Anadolu| 49.07772020725388|\n",
            "|        Karadeniz| 48.75121951219512|\n",
            "|              Ege|47.888888888888886|\n",
            "+-----------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    region_name\n",
        "    ,AVG(YEAR(CURRENT_DATE()) - YEAR(birth_date)) AS age\n",
        "FROM DimCustomer cus\n",
        "INNER JOIN DimRegion reg\n",
        "ON cus.city_id = reg.city_id\n",
        "GROUP BY region_name\n",
        "ORDER BY age DESC\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu3jjravd4qR",
        "outputId": "4a8563fc-0563-46cd-f826-56e7fa94868f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------------+\n",
            "|      region_name|               age|\n",
            "+-----------------+------------------+\n",
            "|          Akdeniz| 50.81521739130435|\n",
            "|     Dogu Anadolu| 50.13095238095238|\n",
            "|Guneydogu Anadolu| 48.58119658119658|\n",
            "|          Marmara|48.189542483660134|\n",
            "|       Ic Anadolu| 48.07772020725388|\n",
            "|        Karadeniz| 47.75121951219512|\n",
            "|              Ege|46.888888888888886|\n",
            "+-----------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    df_cus\n",
        "    .join(df_reg, df_cus.city_id == df_reg.city_id)\n",
        "    .groupBy(\"region_name\").agg(\n",
        "        F.avg(F.year(F.current_date()) - F.year(\"birth_date\")).alias(\"age\")\n",
        "    )\n",
        "    .orderBy(\"age\", ascending=False)\n",
        "    .show()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAN1cuTmd4qR"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px; border-bottom: 4px solid #C2172D;\">\n",
        "    <a id=\"case_studies\">\n",
        "        <h3 style=\"color: #C2172D\">5. Case Studies</h3>\n",
        "    </a>  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX409Qyd4qR"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px;\">\n",
        "    <a id=\"assignment_1\">\n",
        "        <h4 style=\"color: #0D9276\">Assignment 1: Jacket sales per region</h3>\n",
        "    </a>\n",
        "</div>\n",
        "<br>\n",
        "<h4>\n",
        "    Write SparkSQL scripts that results: Region-based total quantity and amount of jacket sales between June and August 2023.\n",
        "</h4>\n",
        "<p>The expected out is as follows: </p>\n",
        "\n",
        "| region_name       | product_type | total_quantity | total_amount |   |\n",
        "|-------------------|--------------|----------------|--------------|---|\n",
        "| Marmara           | Jacket       | 213            | 8358         |   |\n",
        "| Dogu Anadolu      | Jacket       | 284            | 11547        |   |\n",
        "| Guneydogu Anadolu | Jacket       | 176            | 6981         |   |\n",
        "| Ic Anadolu        | Jacket       | 260            | 10496        |   |\n",
        "| Akdeniz           | Jacket       | 162            | 6637         |   |\n",
        "| Karadeniz         | Jacket       | 310            | 12582        |   |\n",
        "| Ege               | Jacket       | 101            | 3953      \n",
        "\n",
        "\n",
        "### External links\n",
        "- https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.join.html\n",
        "- https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html\n",
        "- https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html   |   |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3olWayHud4qS",
        "outputId": "50b5595a-3b83-40c7-a623-2d0b037150b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+--------------+------------+\n",
            "|      region_name|product_type|total_quantity|total_amount|\n",
            "+-----------------+------------+--------------+------------+\n",
            "|          Marmara|      Jacket|           213|        8358|\n",
            "|     Dogu Anadolu|      Jacket|           284|       11547|\n",
            "|Guneydogu Anadolu|      Jacket|           176|        6981|\n",
            "|       Ic Anadolu|      Jacket|           260|       10496|\n",
            "|          Akdeniz|      Jacket|           162|        6637|\n",
            "|        Karadeniz|      Jacket|           310|       12582|\n",
            "|              Ege|      Jacket|           101|        3953|\n",
            "+-----------------+------------+--------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#sparksql çözümüm:\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "    DimRegion.region_name,\n",
        "    DimProduct.product_type,\n",
        "    SUM(FactSale.quantity) AS total_quantity,\n",
        "    SUM(FactSale.total_amt) AS total_amount\n",
        "    FROM DimProduct\n",
        "    JOIN FactSale ON DimProduct.product_id = FactSale.product_id\n",
        "    JOIN DimCustomer ON FactSale.customer_id = DimCustomer.customer_id\n",
        "    JOIN DimRegion ON DimCustomer.city_id = DimRegion.city_id\n",
        "    JOIN DimDate ON FactSale.date = DimDate.date\n",
        "    WHERE DimProduct.product_type = 'Jacket'\n",
        "    AND DimDate.year = 2023\n",
        "    AND DimDate.month BETWEEN 6 AND 8\n",
        "    GROUP BY DimRegion.region_name, DimProduct.product_type\n",
        "\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pyspark çözümüm:\n",
        "from pyspark.sql.functions import col\n",
        "#-- kolaylık olması açısından tablolara alias verdim\n",
        "result=(\n",
        "    df_pro.alias(\"DimProduct\")\n",
        "    .join(\n",
        "        df_sal.alias(\"FactSale\"),\n",
        "        col(\"DimProduct.product_id\") == col(\"FactSale.product_id\"),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .join(\n",
        "        df_cus.alias(\"DimCustomer\"),\n",
        "        col(\"FactSale.customer_id\") == col(\"DimCustomer.customer_id\"),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .join(\n",
        "        df_reg.alias(\"DimRegion\"),\n",
        "        col(\"DimCustomer.city_id\") == col(\"DimRegion.city_id\"),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .join(\n",
        "        df_date.alias(\"DimDate\"),\n",
        "        col(\"FactSale.date\") == col(\"DimDate.date\"),\n",
        "        \"inner\"\n",
        "    )\n",
        "    .filter(\n",
        "        (col(\"DimProduct.product_type\") == \"Jacket\") &\n",
        "        (col(\"DimDate.year\") == 2023) &\n",
        "        (col(\"DimDate.month\").between(6, 8))\n",
        "    )\n",
        "    .groupBy(\"DimRegion.region_name\", \"DimProduct.product_type\")\n",
        "    .agg(\n",
        "        sum(\"FactSale.quantity\").alias(\"total_quantity\"),\n",
        "        sum(\"FactSale.total_amt\").alias(\"total_amount\")\n",
        "    )\n",
        "    .select(\n",
        "        \"DimRegion.region_name\",\n",
        "        \"DimProduct.product_type\",\n",
        "        \"total_quantity\",\n",
        "        \"total_amount\"\n",
        "    )\n",
        ")\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqEl_57ZfJg9",
        "outputId": "276d2678-8823-458a-d0e4-c4dac4fc1c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+--------------+------------+\n",
            "|      region_name|product_type|total_quantity|total_amount|\n",
            "+-----------------+------------+--------------+------------+\n",
            "|          Marmara|      Jacket|           213|        8358|\n",
            "|     Dogu Anadolu|      Jacket|           284|       11547|\n",
            "|Guneydogu Anadolu|      Jacket|           176|        6981|\n",
            "|       Ic Anadolu|      Jacket|           260|       10496|\n",
            "|          Akdeniz|      Jacket|           162|        6637|\n",
            "|        Karadeniz|      Jacket|           310|       12582|\n",
            "|              Ege|      Jacket|           101|        3953|\n",
            "+-----------------+------------+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nByiUYbud4qS"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px;\">\n",
        "    <a id=\"assignment_2\">\n",
        "        <h4 style=\"color: #0D9276\">Assignment 2: Maximum turnover of the retailer regions</h3>\n",
        "    </a>\n",
        "</div>\n",
        "<br>\n",
        "<h4>\n",
        "    Find the maximum turnover region of each retailer, and obtain total amount for each retailer and region.\n",
        "</h4>\n",
        "<p>The expected out is as follows: </p>\n",
        "\n",
        "| retailer_id | retailer_name | region_name | total_amount |\n",
        "|-------------|---------------|-------------|--------------|\n",
        "| 1           | A             | Karadeniz   | 42642        |\n",
        "| 2           | B             | Ic Anadolu  | 71689        |\n",
        "| 3           | C             | Ic Anadolu  | 11995        |\n",
        "| 4           | C             | Karadeniz   | 16081        |\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19xOBOlwd4qS",
        "outputId": "cbbae9ec-0581-47ef-df26-b9142629d69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+------------+\n",
            "|retailer_id|retailer_name|region_name|total_amount|\n",
            "+-----------+-------------+-----------+------------+\n",
            "|          1|            A|  Karadeniz|       42642|\n",
            "|          2|            B| Ic Anadolu|       71689|\n",
            "|          3|            C| Ic Anadolu|       11995|\n",
            "|          4|            D|  Karadeniz|       16081|\n",
            "+-----------+-------------+-----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#sparksql çözümüm\n",
        "\n",
        "query = \"\"\"\n",
        "WITH tablo AS (\n",
        "  -- \"tablo\" adında geçici bir tablo oluşturdum ileride istediğim sütunları buradan seçeceğim\n",
        "    SELECT\n",
        "        DimRetailer.retailer_id,\n",
        "        DimRetailer.retailer_name,\n",
        "        DimRegion.region_name,\n",
        "        SUM(FactSale.total_amt) AS total_amount,\n",
        "        ROW_NUMBER() OVER (PARTITION BY DimRetailer.retailer_id ORDER BY SUM(FactSale.total_amt) DESC) AS retailerbest  -- en yüksek satışı ROW_NUMBER fonksiyonu ile buldum : \"retailerbest\"\n",
        "                                                                                                              -- retailer_id' ye göre gruplama yaptım ve büyükten küçüğe sıraladım\n",
        "    FROM FactSale\n",
        "    LEFT JOIN DimRetailer ON FactSale.retailer_id = DimRetailer.retailer_id\n",
        "    LEFT JOIN DimCustomer ON FactSale.customer_id = DimCustomer.customer_id\n",
        "    LEFT JOIN DimRegion ON DimCustomer.city_id = DimRegion.city_id\n",
        "    GROUP BY DimRetailer.retailer_id, DimRetailer.retailer_name, DimRegion.region_name\n",
        ")\n",
        "SELECT\n",
        "    retailer_id,\n",
        "    retailer_name,\n",
        "    region_name,\n",
        "    total_amount\n",
        "FROM tablo\n",
        "WHERE retailerbest = 1\n",
        "ORDER BY retailer_id;\n",
        "\"\"\"\n",
        "result = spark.sql(query)\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY9S0EIud4qS",
        "outputId": "abbc3d19-0534-4347-ea74-c624dc19ce5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+------------+\n",
            "|retailer_id|retailer_name|region_name|total_amount|\n",
            "+-----------+-------------+-----------+------------+\n",
            "|          1|            A|  Karadeniz|       42642|\n",
            "|          2|            B| Ic Anadolu|       71689|\n",
            "|          3|            C| Ic Anadolu|       11995|\n",
            "|          4|            D|  Karadeniz|       16081|\n",
            "+-----------+-------------+-----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#pyspark çözümüm\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "sales_data = (\n",
        "    df_sal\n",
        "    .join(df_ret, \"retailer_id\")\n",
        "    .join(df_cus, \"customer_id\")\n",
        "    .join(df_reg, df_cus.city_id == df_reg.city_id)\n",
        "    .groupby(\"retailer_id\", \"retailer_name\", \"region_name\")\n",
        "    .agg(F.sum(\"total_amt\").alias(\"total_amount\"))\n",
        ")\n",
        "\n",
        "window_spec = Window.partitionBy(\"retailer_id\").orderBy(F.desc(\"total_amount\")) #en fazla satış yapan en üstte olacak\n",
        "result = sales_data.withColumn(\"rank\", F.row_number().over(window_spec)).filter(F.col(\"rank\") == 1) #en fazla satış yapan bölge 1 numaralı olacağı için o bölgeleri seçiyorum\n",
        "result.select(\"retailer_id\", \"retailer_name\", \"region_name\", \"total_amount\").show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "WITH tablo AS (\n",
        "    SELECT\n",
        "        DimRetailer.retailer_id,\n",
        "        DimRetailer.retailer_name,\n",
        "        DimRegion.region_name,\n",
        "        SUM(FactSale.total_amt) AS total_amount,\n",
        "        RANK() OVER (PARTITION BY DimRetailer.retailer_id ORDER BY SUM(FactSale.total_amt) DESC) AS retailerbest\n",
        "    FROM FactSale\n",
        "    LEFT JOIN DimRetailer ON FactSale.retailer_id = DimRetailer.retailer_id\n",
        "    LEFT JOIN DimCustomer ON FactSale.customer_id = DimCustomer.customer_id\n",
        "    LEFT JOIN DimRegion ON DimCustomer.city_id = DimRegion.city_id\n",
        "    GROUP BY DimRetailer.retailer_id, DimRetailer.retailer_name, DimRegion.region_name\n",
        ")\n",
        "SELECT\n",
        "    retailer_id,\n",
        "    retailer_name,\n",
        "    region_name,\n",
        "    total_amount\n",
        "FROM tablo\n",
        "WHERE retailerbest = 1\n",
        "ORDER BY retailer_id;\n",
        "\n",
        "\"\"\"\n",
        "# Execute the query using spark.sql\n",
        "result = spark.sql(query)\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCCERt7gfOf2",
        "outputId": "34a204d6-fa5b-4afe-9849-c85b28865c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+------------+\n",
            "|retailer_id|retailer_name|region_name|total_amount|\n",
            "+-----------+-------------+-----------+------------+\n",
            "|          1|            A|  Karadeniz|       42642|\n",
            "|          2|            B| Ic Anadolu|       71689|\n",
            "|          3|            C| Ic Anadolu|       11995|\n",
            "|          4|            D|  Karadeniz|       16081|\n",
            "+-----------+-------------+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***ENİSE AHSEN KARADAĞ***"
      ],
      "metadata": {
        "id": "C2efn_jgQeH-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
